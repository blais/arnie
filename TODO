=================
   TODO: arnie
=================

Bugs from Uche
--------------


  On Sat, 2005-11-12 at 10:34 -0500, Martin Blais wrote:
  > It's the MD5 sum that seems to be crashing.
  >
  > Can you try the following:
  > 1. split the md5.new(...) line in many statements
  >
  >   -> identify if it's the read or if it's the md5 that crashes
  >
  > 2. put a print statement for the current file
  >
  >    -> to identify which file makes it crash
  >    -> list the properties of that file
  >
  > With this info I might be able to do something.
  > thx
  
  It's dying on a huge file:
  
  Handling file /home/uche/media/dvd/rolie/vob/001/rolie-002.vob
  Traceback (most recent call last):
   File "/usr/bin/arnie-archive", line 515, in ?
     sys.exit(main())
   File "/usr/bin/arnie-archive", line 404, in main
     (alldirs, incrdirs,
   File "/usr/bin/arnie-archive", line 182, in find_files
     t = f.read()
  MemoryError
  
  # ls -l /home/uche/media/dvd/rolie/vob/001/rolie-002.vob
  -rw-r--r--  1 uche uche 1073741824 Jun 23
  23:24 /home/uche/media/dvd/rolie/vob/001/rolie-002.vob
  
  It definitely seems to slow down when trudging through large files.  I
  wonder whether it's worth a config option to skip the MD5 check for
  files above a certain size.
  
  > "Visiting... ome"
  > >
  > > Should be "home"
  >
  > Actually, this may be a major bug, and this may be the cause for the
  > other problem.
  >
  > And can you apply this change and rerun and send some of the output?
  
  XXX /home ome
  Visiting... ome
  XXX /home/lost+found ome/lost+found
  Visiting... ome/lost+found
  XXX /home/uche ome/uche
  Visiting... ome/uche
  
  That seems to be the consistent pattern.
  
  Thanks.


Misc Ideas
----------

- Print size of every file added to the backup.
- Support user/group file attributes (and change of).

- Add uid, gid, ctime, mtime, and a flags array to file info.



Slow Operation
--------------

Implement alternate unpacking method, untarring files one on top of the
other and removing unwanted files later.

- Note from Mukund <muks@mukund.org>::

   One minor inconvenience that I do notice is that restore times are
   very very slow (almost unusably slow) when a directory with a large
   number of files such as a Maildir tree are involved. I guess this is
   due to tar archive parsing on a per-file basis through Python's
   library and I remember reading somewhere on your website that you
   were thinking of untarring all of the backup archive in one go and
   then just picking up whatever files one wanted. I'd be grateful if
   you implement this feature.



Tracking new attributes and Storing attributes separately from contents
-----------------------------------------------------------------------

Ideas from Harry Flink for desired features:

  There are still some features which might be good to add some day:

  1. uid/gid/mode changes shouldn't neccessarily add the whole file,
     if file data (MD5) is not changed, just the file's meta info.

  2. GPG-files should be extracted in fly to avoid making duplicates
     from the backups for extraction. I'm not sure how exactly this
     could be done, but I hope that somehow.

  3. I haven't tested whether modification times are stored and
     restored, but still it would be great to add them in .arniehistory.

  4. Maybe ACL-support someday, but I dont use them currently.
  

For (1) I would use a flag, that tells the restorer to "keep searching backwards
in time" for that one file, but which marks the attributes to be applied after.
This will require some more thinking, maybe all attributes should behave in this
way (i.e. if only mode changes, then no need to store the file again either).

I think the next modification to arnie will be this:  I will add uid, gid,
ctime, mtime and an array of flags to each file info.  This will allow me to
implement future features without having to change the format, and thus to
remain backwards compatible.

cheers,

Testing for uid/gid changes
---------------------------

Testing uid/gid's::

  From Harry Flink:

  > Yes, I noticed that the problem is only in incremental changes.
  > But if I'm using this in production server, it might save some
  > time to track the changes too. Also this minimizes one side risk:
  > If you try to restore backup with non-root user account, the
  > uid/gid are not set everytime correctly. I even restored the
  > archive with SUDO at /tmp/testrestore and still the owner was
  > not updated. With root account it works properly, but this new
  > uid/gid tracking saved me from lot a trouble already, because
  > it told me that something was wrong and I was able to track
  > down that restoring with root account there are not such problems
  > at all.
  
  Good note.  I will use this to build the tests (I will include a test with sudo).



  > The flag is a good idea.  In restore you could build a
  > statuschanges={} -dict and when the flag is found (I mean the
  > flag to notify that content shouldnt be added, but just
  > perm/time/owner etc is being changed), add the filename to the
  > dict with final values and continue restoring normally. Exception
  > to this is that if filename is already in statuschanges, then
  > dont modify statuschanges -item anymore for that file. After
  > restoring everything, modify file status (perm/time/owner) of all
  > items in dictionary.  Also we should return the dictionary from
  > restore to pass it to the verify (or modify something else, so
  > that verify knows the correct values).



Compressing Backups
-------------------

Existing backup archives could be joined and compressed at a new date, easily,
by writing a new program which would be a variation on arnie-restore.
